{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7851d0c7-1aa7-45c5-828b-c34b800cc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901f53a9-2c78-4f15-bfdc-753aa61b5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNormalNoise:\n",
    "    def __init__(self, mean=0, std=1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.shape) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f\"(mean={self.mean}, std={self.std})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5dfbd7-b304-4d71-b526-ea0c32638b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda t: (t * 2) - 1)  # Scale between [-1, 1]\n",
    "])\n",
    "\n",
    "data_transform = transforms.Compose(data_transforms)\n",
    "train_set = torchvision.datasets.FashionMNIST(\"data\", download=True, train=True, transform=data_transforms)\n",
    "test_set = torchvision.datasets.FashionMNIST(\"data\", download=True, train=False, transform=data_transforms)\n",
    "data = torch.utils.data.ConcatDataset([train_set, test_set])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0434783c-6251-4750-b23f-37dc6fc1282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1, padding=1):\n",
    "        super(DownBlock, self).__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        ]\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837b460c-ed81-40e0-a5d7-e1aa36fbf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1, padding=1, strideT=2, out_paddingT=1):\n",
    "        super(UpBlock).__init__()\n",
    "        # 2 * in_chs for concatednated skip connection\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(2 * in_ch, out_ch, kernel_size, strideT, padding, out_paddingT),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((x, skip), 1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02328eb8-95b4-4d45-90f3-15065af03b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, img_ch):\n",
    "        super(UNet).__init__()\n",
    "        down_chs = (16, 32, 64)\n",
    "        up_chs = down_chs[::-1]  # Reverse of the down channels\n",
    "        latent_image_size = IMG_SIZE // 4 # 2 ** (len(down_chs) - 1)\n",
    "\n",
    "        # Inital convolution\n",
    "        self.down0 = nn.Sequential(\n",
    "            nn.Conv2d(img_ch, down_chs[0], 3, padding=1),\n",
    "            nn.BatchNorm2d(down_chs[0]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Downsample\n",
    "        self.down1 = DownBlock(down_chs[0], down_chs[1])\n",
    "        self.down2 = DownBlock(down_chs[1], down_chs[2])\n",
    "        self.to_vec = nn.Sequential(nn.Flatten(), nn.ReLU())\n",
    "        \n",
    "        # Embeddings\n",
    "        self.dense_emb = nn.Sequential(\n",
    "            nn.Linear(down_chs[2]*latent_image_size**2, down_chs[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(down_chs[1], down_chs[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(down_chs[1], down_chs[2]*latent_image_size**2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Upsample\n",
    "        self.up0 = nn.Sequential(\n",
    "            nn.Unflatten(1, (up_chs[0], latent_image_size, latent_image_size)),\n",
    "            nn.Conv2d(up_chs[0], up_chs[0], 3, padding=1),\n",
    "            nn.BatchNorm2d(up_chs[0]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.up1 = UpBlock(up_chs[0], up_chs[1])\n",
    "        self.up2 = UpBlock(up_chs[1], up_chs[2])\n",
    "\n",
    "        # Match output channels\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(up_chs[-1], up_chs[-1], 3, 1, 1),\n",
    "            nn.BatchNorm2d(up_chs[-1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(up_chs[-1], img_ch, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        down0 = self.down0(x)\n",
    "        down1 = self.down1(down0)\n",
    "        down2 = self.down2(down1)\n",
    "        latent_vec = self.to_vec(down2)\n",
    "\n",
    "        up0 = self.up0(latent_vec)\n",
    "        up1 = self.up1(up0, down2)\n",
    "        up2 = self.up2(up1, down1)\n",
    "        return self.out(up2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
